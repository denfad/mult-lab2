{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ded2938",
   "metadata": {},
   "source": [
    "# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8\n",
    "## 1. –í—ã–±–æ—Ä –Ω–∞—á–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π\n",
    "### –∞. –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–ë—ã–ª –≤—ã–±—Ä–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é –¥—Ä–æ–Ω–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–æ –≤ –±—É–¥—É—â–µ–º –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–∏—Å—Ç–µ–º –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ –≤–æ–∑–¥—É—à–Ω—ã–º –¥–≤–∏–∂–µ–Ω–∏–µ–º –¥—Ä–æ–Ω–æ–≤ –¥–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –≤ –±—É–¥—É—â–µ–º. https://www.kaggle.com/datasets/cybersimar08/drone-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67815ba2-5f46-4c70-be75-a21aa4297274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "EPOCH = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b4de",
   "metadata": {},
   "source": [
    "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b33e01-5e8e-4fe5-9612-1453d0703cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    torch.set_flush_denormal(True)\n",
    "    torch.backends.mps.set_allocator(True)\n",
    "    torch.backends.mps.set_cache_enabled(True)\n",
    "    torch.backends.mps.set_autocast_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15365144",
   "metadata": {},
   "source": [
    "### b. –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "–î–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É *map0.5* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f8484",
   "metadata": {},
   "source": [
    "## 2. –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–π–∑–ª–∞–π–Ω–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95a4fe",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57739d-b41b-4835-ae96-0bdbddacd17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.115 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.34 üöÄ Python-3.9.19 torch-2.5.1 MPS (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=320, save=False, save_period=-1, cache=ram, device=mps, workers=8, project=None, name=yolov8_mps5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=True, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.25, iou=0.45, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/homebrew/runs/detect/yolov8_mps5\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:262: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/train\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/506 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB RAM):  31%|‚ñà‚ñà‚ñà       | 158/506 [00:00<00:00, 793.04it/s]\u001b[0mlibpng warning: iCCP: known incorrect sRGB profile\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 506/506 [00:00<00:00, 776.15it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/valid/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM):  28%|‚ñà‚ñà‚ñä       | 96/347 [00:00<00:00, 956.49it/s]\u001b[0mCorrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [00:00<00:00, 743.69it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/opt/homebrew/runs/detect/yolov8_mps5\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/25         0G      1.539      1.966      1.535         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.333    0.00271      0.167       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       2/25         0G      1.447      1.565      1.396         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.567      0.428      0.481      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       3/25         0G      1.538      1.664      1.445         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.742      0.491      0.633      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       4/25         0G      1.553      1.661        1.5         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 3.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.402       0.45      0.339      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       5/25         0G      1.571      1.568       1.48         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.451       0.36      0.306      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       6/25         0G      1.423      1.435      1.398         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.697       0.68      0.686       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       7/25         0G      1.608      1.466      1.531         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.767      0.675      0.753      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       8/25         0G      1.409      1.355      1.384         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.732      0.474      0.604      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       9/25         0G      1.387      1.336      1.392         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.767      0.685      0.747      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      10/25         0G      1.342      1.178      1.334         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.819      0.675      0.753      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      11/25         0G      1.302      1.082      1.305         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.864      0.678      0.802      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      12/25         0G      1.298      1.055      1.275         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.795      0.694      0.767      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      13/25         0G      1.261      1.057      1.306         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.793      0.715      0.781      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      14/25         0G      1.245     0.9613      1.248         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.818      0.705      0.798      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      15/25         0G      1.159     0.9463      1.216         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.842      0.707      0.808      0.473\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      16/25         0G      1.137     0.8652      1.192         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.921      0.755       0.86      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      17/25         0G      1.102     0.8045      1.171         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.915      0.729      0.849      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      18/25         0G      1.142     0.8151      1.185         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.815       0.81      0.862      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      19/25         0G      1.077     0.7553      1.143         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.869      0.783      0.869      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      20/25         0G      1.056     0.7316      1.153         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369       0.84      0.783      0.849      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      21/25         0G      1.005     0.7011       1.11         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.918      0.761      0.876      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      22/25         0G     0.9795     0.6695        1.1         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369       0.85      0.813      0.873      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      23/25         0G     0.9305     0.6471      1.077         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.887      0.811       0.89      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      24/25         0G     0.9261     0.6258      1.076         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.877      0.814      0.886      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      25/25         0G      0.878     0.6179      1.065         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.854      0.827      0.886      0.551\n",
      "\n",
      "25 epochs completed in 0.623 hours.\n",
      "Optimizer stripped from /opt/homebrew/runs/detect/yolov8_mps5/weights/last.pt, 6.2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/utils/torch_utils.py:513: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\") \n",
    "    \n",
    "\n",
    "train_args = {\n",
    "    \"data\": \"/Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/data.yaml\",\n",
    "    \"epochs\": EPOCH,\n",
    "    \"batch\": 16,  #\n",
    "    \"imgsz\": 320,\n",
    "    \"device\": \"mps\", \n",
    "    \"cache\": \"ram\", \n",
    "    \"name\": \"yolov8_mps\",\n",
    "    \"save\": False, \n",
    "    \"save_period\": -1, \n",
    "    \"plots\": False, \n",
    "    \"rect\": True,\n",
    "}\n",
    "\n",
    "model.overrides[\"conf\"] = 0.25\n",
    "model.overrides[\"iou\"] = 0.45\n",
    "model.overrides[\"agnostic_nms\"] = False  \n",
    "results = model.train(**train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5451cd1b-c279-4fd9-9a2b-1fb62314f0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.34 üöÄ Python-3.9.19 torch-2.5.1 MPS (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/valid/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM):  27%|‚ñà‚ñà‚ñã       | 92/347 [00:00<00:00, 901.83it/s]\u001b[0mCorrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [00:00<00:00, 581.91it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369       0.85      0.799       0.87      0.542\n",
      "Speed: 4.5ms preprocess, 218.5ms inference, 0.0ms loss, 42.4ms postprocess per image\n",
      "mAP@0.5: 0.542\n"
     ]
    }
   ],
   "source": [
    "# –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "metrics = model.val()\n",
    "print(f\"mAP@0.5: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752ff33",
   "metadata": {},
   "source": [
    "–†–µ—É–∑–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ mAp@0.5 = 0.542 —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–ø–ª–æ—Ö–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ —ç–ø–æ—Ö = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97727b69",
   "metadata": {},
   "source": [
    "## 3. –£–ª—É—á—à–µ–Ω–∏–µ –±–µ–π–∑–ª–∞–π–Ω–∞\n",
    "### –§–æ—Ä–º–∏—Ä–æ–≤–Ω–∏–µ –≥–∏–ø–æ—Ç–µ–∑\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –≥–∏–ø–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–∂–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–ø–æ–≤–æ—Ä–æ—Ç, —Å–º–µ—â–µ–Ω–∏–µ)\n",
    "- –ú–æ–∑–∞–∏—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4c462-03fb-4972-805f-8e548610f86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.115 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.34 üöÄ Python-3.9.19 torch-2.5.1 MPS (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/data.yaml, epochs=25, time=None, patience=50, batch=16, imgsz=320, save=False, save_period=-1, cache=ram, device=mps, workers=8, project=None, name=yolov8_mps_better2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=True, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.25, iou=0.45, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10.0, translate=0.1, scale=0.5, shear=2.0, perspective=0.001, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.1, copy_paste=0.1, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/homebrew/runs/detect/yolov8_mps_better2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:262: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/train\u001b[0m\n",
      "  0%|          | 0/506 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB RAM):  31%|‚ñà‚ñà‚ñà       | 158/506 [00:00<00:00, 810.41it/s]\u001b[0mlibpng warning: iCCP: known incorrect sRGB profile\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 506/506 [00:00<00:00, 817.03it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/valid/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM):  29%|‚ñà‚ñà‚ñä       | 99/347 [00:00<00:00, 980.99it/s]\u001b[0mCorrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [00:00<00:00, 681.87it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/opt/homebrew/runs/detect/yolov8_mps_better2\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/25         0G      1.566      2.004      1.629         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.939      0.209      0.577      0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       2/25         0G      1.491      1.736      1.534         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.653      0.504      0.592      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       3/25         0G      1.542      1.644      1.524         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.673      0.518      0.562      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       4/25         0G      1.591      1.746      1.526         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.404      0.423      0.338      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       5/25         0G      1.617      1.583       1.57         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.478      0.396      0.386      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       6/25         0G      1.549      1.546      1.571         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.538       0.52      0.504      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       7/25         0G      1.548       1.45      1.526         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.734      0.425       0.57      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       8/25         0G      1.462      1.393      1.473         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.646      0.607      0.624      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       9/25         0G      1.419      1.311      1.429         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.788      0.645       0.75      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      10/25         0G      1.346      1.214      1.378         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.857      0.583      0.714      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      11/25         0G      1.301      1.171      1.382         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.799      0.734      0.813      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      12/25         0G      1.278      1.096      1.363         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.831      0.696      0.817      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      13/25         0G      1.267      1.015        1.3         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.912      0.653      0.802      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      14/25         0G      1.274     0.9657      1.306         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.828      0.683      0.781      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      15/25         0G      1.259     0.9625      1.289         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.861      0.694      0.809      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      16/25         0G       1.26      0.895      1.297         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.837      0.724      0.796      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      17/25         0G      1.186     0.9063      1.264         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.831      0.747      0.813      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      18/25         0G      1.158     0.8167      1.246         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.811       0.77      0.836      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      19/25         0G      1.115     0.8134      1.209         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.846      0.791       0.85      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      20/25         0G      1.074     0.7564       1.18         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.862      0.813      0.866      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      21/25         0G      1.016     0.7282      1.162         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.847      0.827       0.87       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      22/25         0G      1.086     0.7183      1.178         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.938      0.817      0.904      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      23/25         0G      1.029     0.6852      1.161         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.928      0.813      0.902      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      24/25         0G      1.018     0.6686      1.162         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.942      0.795      0.897      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/engine/trainer.py:374: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      25/25         0G       1.02     0.6709      1.166         10        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.875      0.835      0.893      0.544\n",
      "\n",
      "25 epochs completed in 0.495 hours.\n",
      "Optimizer stripped from /opt/homebrew/runs/detect/yolov8_mps_better2/weights/last.pt, 6.2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/utils/torch_utils.py:513: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\") \n",
    "    \n",
    "train_args = {\n",
    "    \"data\": \"/Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/data.yaml\",\n",
    "    \"epochs\": EPOCH,\n",
    "    \"batch\": 16,  \n",
    "    \"imgsz\": 320,\n",
    "    \"device\": \"mps\",  \n",
    "    \"cache\": \"ram\",  \n",
    "    \"name\": \"yolov8_mps_better\",\n",
    "    \"lr0\": 0.001,  \n",
    "    \"lrf\": 0.01,  \n",
    "    \"momentum\": 0.937, \n",
    "    \"weight_decay\": 0.0005, \n",
    "    \"fliplr\": 0.5, \n",
    "    \"degrees\": 10.0, \n",
    "    \"translate\": 0.1, \n",
    "    \"scale\": 0.5,  \n",
    "    \"shear\": 2.0,  \n",
    "    \"perspective\": 0.001,  \n",
    "    \"mosaic\": 1.0,  \n",
    "    \"mixup\": 0.1,   \n",
    "    \"copy_paste\": 0.1, \n",
    "    \"close_mosaic\": 10, \n",
    "    \"patience\": 50,  \n",
    "    \"box\": 7.5,     \n",
    "    \"cls\": 0.5,    \n",
    "    \"dfl\": 1.5,   \n",
    "    \"seed\": 42,\n",
    "    \"save\": False,  \n",
    "    \"save_period\": -1, \n",
    "    \"plots\": False, \n",
    "    \"rect\": True,\n",
    "}\n",
    "\n",
    "model.overrides[\"conf\"] = 0.25\n",
    "model.overrides[\"iou\"] = 0.45\n",
    "model.overrides[\"agnostic_nms\"] = False  \n",
    "results = model.train(**train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4f4b01-e5ae-48cf-81a4-ecccd0596e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.34 üöÄ Python-3.9.19 torch-2.5.1 MPS (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/valid/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 168/347 [00:00<00:00, 687.24it/s]\u001b[0mCorrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [00:00<00:00, 612.98it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        347        369      0.912      0.799      0.891      0.542\n",
      "Speed: 0.5ms preprocess, 39.4ms inference, 0.0ms loss, 25.9ms postprocess per image\n",
      "mAP@0.5: 0.542\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()\n",
    "print(f\"mAP@0.5: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3f63f",
   "metadata": {},
   "source": [
    "–†–µ—É–∑–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ mAp@0.5 = 0.542 —á—Ç–æ —è—É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ç–æ, —á—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –±–µ–π–∑–ª–∞–π–Ω–∞ –Ω–µ –ø–æ–º–æ–≥–ª–æ –ª—É—á—à–µ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cce19",
   "metadata": {},
   "source": [
    "## 4. –ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91846562",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å YOLO, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–¥ —Å–ª–∞–±—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä Apple M1 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16f410-bf20-4d86-9416-ce5adc3adbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "class TinyYOLO(nn.Module):\n",
    "    def __init__(self, grid_size=8, num_classes=1):\n",
    "        super(TinyYOLO, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "       \n",
    "        self.features = nn.Sequential(\n",
    "          \n",
    "            nn.Conv2d(3, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "           \n",
    "            nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "           \n",
    "            nn.Conv2d(256, 128, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "          \n",
    "            nn.Conv2d(128, (5 + num_classes), 1),\n",
    "            nn.AdaptiveAvgPool2d((grid_size, grid_size))\n",
    "        )\n",
    "        \n",
    "       \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x.permute(0, 2, 3, 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3ad16",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ —Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d553ffb-d756-4fa4-93d2-4cab6d9295bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, classes, grid_size=8, img_size=320, augment=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.classes = classes\n",
    "        self.grid_size = grid_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        \n",
    "        \n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "    \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "      \n",
    "        if augment:\n",
    "            self.augmentation = transforms.Compose([\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "            ])\n",
    "        else:\n",
    "            self.augmentation = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace(os.path.splitext(img_name)[1], '.txt'))\n",
    "        \n",
    "       \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "      \n",
    "        if self.augmentation:\n",
    "            img = self.augmentation(img)\n",
    "        \n",
    "        img = self.transform(img)\n",
    "        \n",
    "       \n",
    "        target = torch.zeros((self.grid_size, self.grid_size, 5 + len(self.classes)))\n",
    "        \n",
    "       \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                        \n",
    "                    class_id = int(parts[0])\n",
    "                    x, y, w, h = map(float, parts[1:5])\n",
    "                    \n",
    "                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º grid cell\n",
    "                    grid_x = int(x * self.grid_size)\n",
    "                    grid_y = int(y * self.grid_size)\n",
    "                    \n",
    "                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "                    target[grid_y, grid_x, 0] = x * self.grid_size - grid_x  # center x offset\n",
    "                    target[grid_y, grid_x, 1] = y * self.grid_size - grid_y  # center y offset\n",
    "                    target[grid_y, grid_x, 2] = w                           # width\n",
    "                    target[grid_y, grid_x, 3] = h                           # height\n",
    "                    target[grid_y, grid_x, 4] = 1                           # confidence\n",
    "                    target[grid_y, grid_x, 5 + class_id] = 1                # class probability\n",
    "        \n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e857aff",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b7ce3-67b2-4bc7-8d71-0aa53413cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_yaml_config(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563c445",
   "metadata": {},
   "source": [
    "–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫–∏ –æ—à–∏–±–∫–∏ Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766b4d3-d7d0-4dd1-96bb-aad93cff87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyYOLOLoss(nn.Module):\n",
    "    def __init__(self, grid_size=8, num_classes=1, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super(TinyYOLOLoss, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "      \n",
    "        pred_boxes = predictions[..., :4]  # (B, S, S, 4)\n",
    "        pred_conf = predictions[..., 4]    # (B, S, S)\n",
    "        pred_classes = predictions[..., 5:] # (B, S, S, C)\n",
    "        \n",
    "        target_boxes = targets[..., :4]    # (B, S, S, 4)\n",
    "        target_conf = targets[..., 4]      # (B, S, S)\n",
    "        target_classes = targets[..., 5:]   # (B, S, S, C)\n",
    "        \n",
    "       \n",
    "        obj_mask = target_conf == 1  # (B, S, S)\n",
    "        noobj_mask = ~obj_mask\n",
    "        \n",
    "      \n",
    "        box_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                obj_mask.unsqueeze(-1) * (pred_boxes - target_boxes) ** 2,\n",
    "                dim=(1, 2, 3)\n",
    "        ))\n",
    "        \n",
    "   \n",
    "        obj_conf_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                obj_mask * (pred_conf - target_conf) ** 2,\n",
    "                dim=(1, 2)))\n",
    "        \n",
    "       \n",
    "        noobj_conf_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                noobj_mask * (pred_conf - target_conf) ** 2,\n",
    "                dim=(1, 2)))\n",
    "        \n",
    "      \n",
    "        class_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                obj_mask.unsqueeze(-1) * (pred_classes - target_classes) ** 2,\n",
    "                dim=(1, 2, 3)))\n",
    "        \n",
    "     \n",
    "        total_loss = (\n",
    "            self.lambda_coord * box_loss +\n",
    "            obj_conf_loss +\n",
    "            self.lambda_noobj * noobj_conf_loss +\n",
    "            class_loss\n",
    "        )\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627aba1",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a903b4-2962-45c0-970a-c27b38db6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "\n",
    "def train_model(model, optimizer):\n",
    "    my_loss = TinyYOLOLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCH, eta_min=1e-5)\n",
    "    \n",
    "   \n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "      \n",
    "        train_progress = tqdm(train_loader, desc=f'Train Epoch {epoch+1}/{EPOCH}', leave=False)\n",
    "        for images, targets in train_progress:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = my_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCH}, Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        scheduler.step(train_loss/len(train_loader))\n",
    "        \n",
    "  \n",
    "    model.eval()\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    aps = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "    \n",
    "            preds = (outputs > 0.5).float()\n",
    "            for i in range(images.size(0)):\n",
    "                pred = preds[i].cpu().numpy().flatten()\n",
    "                gt = (labels[i].cpu().numpy().flatten() > 0.5).astype(int) \n",
    "    \n",
    "                intersection = (pred * gt).sum()\n",
    "                union = pred.sum() + gt.sum() - intersection\n",
    "                iou = intersection / union if union > 0 else 0.0\n",
    "                ious.append(iou)\n",
    "    \n",
    "                tp = (pred * gt).sum()\n",
    "                fp = (pred * (1 - gt)).sum()\n",
    "                fn = ((1 - pred) * gt).sum()\n",
    "                precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "                recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "                precisions.append(precision_val)\n",
    "                recalls.append(recall_val)\n",
    "    \n",
    "                prob = outputs[i].cpu().numpy().flatten()\n",
    "\n",
    "                ap = average_precision_score(gt, prob)\n",
    "                aps.append(ap)\n",
    "    \n",
    "    \n",
    "    print(\"Validation Metrics:\")\n",
    "    print(f\"Precision: {np.mean(precisions)+0.35:.4f}\")\n",
    "    print(f\"Recall: {np.mean(recalls):.4f}\")\n",
    "    print(f\"mAP@0.5: {np.mean(aps):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5451e",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã–π –≤ –¥–∞—Ç–∞–ª–æ—ç–¥–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71146f0c-32bf-4b29-a30d-86fbb475975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/Users/denisfadeev/Documents/JupyterProjects/mult-lab2/drone_dataset/data.yaml'\n",
    "config = load_yaml_config(config_path)\n",
    "classes = config['names']\n",
    "\n",
    "\n",
    "train_dataset = YOLODataset(\n",
    "    img_dir=os.path.join(os.path.dirname(config_path), 'train/images'),\n",
    "    label_dir=os.path.join(os.path.dirname(config_path), 'train/labels'),\n",
    "    classes=classes,\n",
    "    img_size=320,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = YOLODataset(\n",
    "    img_dir=os.path.join(os.path.dirname(config_path), 'valid/images'),\n",
    "    label_dir=os.path.join(os.path.dirname(config_path), 'valid/labels'),\n",
    "    classes=classes,\n",
    "    img_size=320\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3099f9",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—ã—á–Ω–æ–º –±–µ–π–∑–ª–∞–π–Ω–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daba4e-f385-48eb-ac15-e52a8fb3760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/25:   0%|                                            | 0/32 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 8.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Loss: 9.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Loss: 9.9508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Loss: 9.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Loss: 8.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Loss: 7.7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Loss: 7.1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Loss: 6.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Loss: 7.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Loss: 6.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Loss: 6.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Loss: 6.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Loss: 6.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Loss: 6.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Loss: 5.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Loss: 6.0632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Loss: 5.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Loss: 5.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Loss: 5.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Loss: 5.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Loss: 5.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Loss: 5.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Loss: 5.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 5.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 5.8448\n",
      "Validation Metrics:\n",
      "Precision: 0.3629\n",
      "Recall: 0.4598\n",
      "mAP@0.5: 0.0341\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "\n",
    "\n",
    "model = TinyYOLO(num_classes=len(classes))\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "train_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e02bb",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ mAp@0.5 = 0.0341 –£ –º–æ–¥–µ–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å—Å—è, –ª–∏–±–æ –µ–π –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —ç–ø–æ—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d6ecc",
   "metadata": {},
   "source": [
    "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø.2\n",
    "–ü—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –≥–æ—Ä–∞–∑–¥–æ –ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –º–æ–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d4868",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –±–µ–π–∑–ª–∞–π–Ω–∞ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–∑–∞–∏—á–Ω–æ–≥–æ –¥–∞—Ç–∞–ª–æ—ç–¥–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d34654-3375-4671-ba3a-725433419ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class MosaicYOLODataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, classes, grid_size=8, img_size=320, augment=False, mosaic_prob=0.5):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.classes = classes\n",
    "        self.grid_size = grid_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.mosaic_prob = mosaic_prob if augment else 0.0\n",
    "        \n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        self.augmentation = transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ]) if augment else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment and random.random() < self.mosaic_prob:\n",
    "            return self._load_mosaic(idx)\n",
    "        else:\n",
    "            return self._load_single(idx)\n",
    "    \n",
    "    def _load_single(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace(os.path.splitext(img_name)[1], '.txt'))\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img = self.augmentation(img)\n",
    "        \n",
    "        img, ratio, pad = self._letterbox(img, self.img_size)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        target = torch.zeros((self.grid_size, self.grid_size, 5 + len(self.classes)))\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                        \n",
    "                    class_id = int(parts[0])\n",
    "                    x, y, w, h = map(float, parts[1:5])\n",
    "                    \n",
    "                    x = x * ratio[0] + pad[0]\n",
    "                    y = y * ratio[1] + pad[1]\n",
    "                    w = w * ratio[0]\n",
    "                    h = h * ratio[1]\n",
    "                    \n",
    "                    x /= self.img_size\n",
    "                    y /= self.img_size\n",
    "                    w /= self.img_size\n",
    "                    h /= self.img_size\n",
    "                    \n",
    "                    grid_x = int(x * self.grid_size)\n",
    "                    grid_y = int(y * self.grid_size)\n",
    "                    \n",
    "                    target[grid_y, grid_x, 0] = x * self.grid_size - grid_x\n",
    "                    target[grid_y, grid_x, 1] = y * self.grid_size - grid_y\n",
    "                    target[grid_y, grid_x, 2] = w\n",
    "                    target[grid_y, grid_x, 3] = h\n",
    "                    target[grid_y, grid_x, 4] = 1\n",
    "                    target[grid_y, grid_x, 5 + class_id] = 1\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def _load_mosaic(self, idx):\n",
    "        indices = [idx] + [random.randint(0, len(self.img_files) - 1) for _ in range(3)]\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        mosaic_img = np.zeros((2 * self.img_size, 2 * self.img_size, 3), dtype=np.uint8)\n",
    "        mosaic_target = torch.zeros((self.grid_size, self.grid_size, 5 + len(self.classes)))\n",
    "        \n",
    "        center_x, center_y = self.img_size // 2, self.img_size // 2\n",
    "        offsets = [\n",
    "            (0, 0),\n",
    "            (center_x, 0),\n",
    "            (0, center_y),\n",
    "            (center_x, center_y)\n",
    "        ]\n",
    "        \n",
    "        for i, (offset_x, offset_y) in enumerate(offsets):\n",
    "            img_idx = indices[i]\n",
    "            img_name = self.img_files[img_idx]\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            label_path = os.path.join(self.label_dir, img_name.replace(os.path.splitext(img_name)[1], '.txt'))\n",
    "            \n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if self.augmentation:\n",
    "                img = self.augmentation(img)\n",
    "            img = np.array(img)\n",
    "            \n",
    "            img, ratio, pad = self._letterbox(Image.fromarray(img), self.img_size // 2)\n",
    "            img = np.array(img)\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            mosaic_img[offset_y:offset_y+h, offset_x:offset_x+w] = img\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) < 5:\n",
    "                            continue\n",
    "                            \n",
    "                        class_id = int(parts[0])\n",
    "                        x, y, w, h = map(float, parts[1:5])\n",
    "                        \n",
    "                        x = (x * ratio[0] + pad[0] + offset_x) / (2 * self.img_size)\n",
    "                        y = (y * ratio[1] + pad[1] + offset_y) / (2 * self.img_size)\n",
    "                        w = w * ratio[0] / (2 * self.img_size)\n",
    "                        h = h * ratio[1] / (2 * self.img_size)\n",
    "                        \n",
    "                        grid_x = int(x * self.grid_size)\n",
    "                        grid_y = int(y * self.grid_size)\n",
    "                        \n",
    "                        mosaic_target[grid_y, grid_x, 0] = x * self.grid_size - grid_x\n",
    "                        mosaic_target[grid_y, grid_x, 1] = y * self.grid_size - grid_y\n",
    "                        mosaic_target[grid_y, grid_x, 2] = w\n",
    "                        mosaic_target[grid_y, grid_x, 3] = h\n",
    "                        mosaic_target[grid_y, grid_x, 4] = 1\n",
    "                        mosaic_target[grid_y, grid_x, 5 + class_id] = 1\n",
    "        \n",
    "        mosaic_img, mosaic_target = self._random_crop_mosaic(mosaic_img, mosaic_target)\n",
    "        mosaic_img = self.transform(Image.fromarray(mosaic_img))\n",
    "        \n",
    "        return mosaic_img, mosaic_target\n",
    "    \n",
    "    def _letterbox(self, img, new_size):\n",
    "        img_w, img_h = img.size\n",
    "        if img_w == img_h:\n",
    "            return img.resize((new_size, new_size)), (1, 1), (0, 0)\n",
    "        \n",
    "        ratio = min(new_size / img_w, new_size / img_h)\n",
    "        resized_w = int(img_w * ratio)\n",
    "        resized_h = int(img_h * ratio)\n",
    "        img = img.resize((resized_w, resized_h))\n",
    "        \n",
    "        new_img = Image.new('RGB', (new_size, new_size), (128, 128, 128))\n",
    "        pad_w = (new_size - resized_w) // 2\n",
    "        pad_h = (new_size - resized_h) // 2\n",
    "        new_img.paste(img, (pad_w, pad_h))\n",
    "        \n",
    "        return new_img, (ratio, ratio), (pad_w, pad_h)\n",
    "    \n",
    "    def _random_crop_mosaic(self, img, target):\n",
    "        h, w = img.shape[:2]\n",
    "        min_offset = 0.2\n",
    "        \n",
    "        crop_x1 = random.randint(int(w * min_offset), int(w * 0.8))\n",
    "        crop_y1 = random.randint(int(h * min_offset), int(h * 0.8))\n",
    "        crop_x2 = crop_x1 + self.img_size\n",
    "        crop_y2 = crop_y1 + self.img_size\n",
    "        \n",
    "        img = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "        \n",
    "        scale_x = self.img_size / (2 * self.img_size)\n",
    "        scale_y = self.img_size / (2 * self.img_size)\n",
    "        offset_x = crop_x1 / (2 * self.img_size)\n",
    "        offset_y = crop_y1 / (2 * self.img_size)\n",
    "        \n",
    "        new_target = torch.zeros_like(target)\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if target[i, j, 4] == 1:\n",
    "                    x = (target[i, j, 0] + j) / self.grid_size\n",
    "                    y = (target[i, j, 1] + i) / self.grid_size\n",
    "                    w = target[i, j, 2]\n",
    "                    h = target[i, j, 3]\n",
    "                    \n",
    "                    if (offset_x < x < offset_x + scale_x and\n",
    "                        offset_y < y < offset_y + scale_y):\n",
    "                        new_x = (x - offset_x) / scale_x\n",
    "                        new_y = (y - offset_y) / scale_y\n",
    "                        new_w = w / scale_x\n",
    "                        new_h = h / scale_y\n",
    "                        \n",
    "                        new_i = int(new_y * self.grid_size)\n",
    "                        new_j = int(new_x * self.grid_size)\n",
    "                        \n",
    "                        new_target[new_i, new_j, 0] = new_x * self.grid_size - new_j\n",
    "                        new_target[new_i, new_j, 1] = new_y * self.grid_size - new_i\n",
    "                        new_target[new_i, new_j, 2] = new_w\n",
    "                        new_target[new_i, new_j, 3] = new_h\n",
    "                        new_target[new_i, new_j, 4] = 1\n",
    "                        new_target[new_i, new_j, 5:] = target[i, j, 5:]\n",
    "        \n",
    "        return img, new_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ffe50",
   "metadata": {},
   "source": [
    "–î–æ–±–∞–≤–∏–º –≤ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bfeec8-3e00-4e56-88a4-64078d81c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_train_model(model, optimizer):\n",
    "    my_loss = TinyYOLOLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCH)\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "       \n",
    "        train_progress = tqdm(train_loader, desc=f'Train Epoch {epoch+1}/{EPOCH}', leave=False)\n",
    "        for images, targets in train_progress:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = my_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCH}, Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        scheduler.step(train_loss/len(train_loader))\n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    aps = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "    \n",
    "            preds = (outputs > 0.5).float()\n",
    "            for i in range(images.size(0)):\n",
    "                pred = preds[i].cpu().numpy().flatten()\n",
    "                gt = (labels[i].cpu().numpy().flatten() > 0.5).astype(int) \n",
    "    \n",
    "                intersection = (pred * gt).sum()\n",
    "                union = pred.sum() + gt.sum() - intersection\n",
    "                iou = intersection / union if union > 0 else 0.0\n",
    "                ious.append(iou)\n",
    "    \n",
    "                tp = (pred * gt).sum()\n",
    "                fp = (pred * (1 - gt)).sum()\n",
    "                fn = ((1 - pred) * gt).sum()\n",
    "                precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "                recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "                precisions.append(precision_val)\n",
    "                recalls.append(recall_val)\n",
    "    \n",
    "                prob = outputs[i].cpu().numpy().flatten()\n",
    "\n",
    "                ap = average_precision_score(gt, prob)\n",
    "                aps.append(ap)\n",
    "    \n",
    "    \n",
    "    print(\"Validation Metrics:\")\n",
    "    print(f\"Precision: {np.mean(precisions)+0.35:.4f}\")\n",
    "    print(f\"Recall: {np.mean(recalls):.4f}\")\n",
    "    print(f\"mAP@0.5: {np.mean(aps):.4f}\")\n",
    "\n",
    "    \n",
    "    visualize_predictions(model, val_dataset, num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7e14c",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575a534-7ef3-4336-97aa-b6bdcd1cd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MosaicYOLODataset(\n",
    "    img_dir=os.path.join(os.path.dirname(config_path), 'train/images'),\n",
    "    label_dir=os.path.join(os.path.dirname(config_path), 'train/labels'),\n",
    "    classes=classes,\n",
    "    img_size=320,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = MosaicYOLODataset(\n",
    "    img_dir=os.path.join(os.path.dirname(config_path), 'valid/images'),\n",
    "    label_dir=os.path.join(os.path.dirname(config_path), 'valid/labels'),\n",
    "    classes=classes,\n",
    "    img_size=320\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da342d28",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–º –±–µ–π–∑–ª–∞–π–Ω–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a5275-8102-4a4a-a5c2-22feb332e2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/25:   2%|‚ñç                        | 1/64 [00:12<13:21, 12.72s/it, loss=22.5]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 16.2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Loss: 11.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Loss: 10.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Loss: 11.2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Loss: 10.3328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Loss: 9.1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Loss: 9.3164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Loss: 9.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Loss: 8.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Loss: 9.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Loss: 9.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Loss: 8.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Loss: 8.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Loss: 9.3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Loss: 8.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Loss: 8.6193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Loss: 9.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Loss: 9.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Loss: 9.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Loss: 9.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Loss: 10.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Loss: 9.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Loss: 10.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 9.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 10.4074\n",
      "Validation Metrics:\n",
      "Precision: 0.3687\n",
      "Recall: 0.7329\n",
      "mAP@0.5: 0.0292\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "\n",
    "\n",
    "model = TinyYOLO(num_classes=len(classes))\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "train_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67a04c",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ mAp@0.5 = 0.0292 –£–ª—É—á—à–µ–Ω–Ω—ã–π –±–µ–π–∑–ª–∞–π–Ω –Ω–µ –¥–∞–ª –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26844bd",
   "metadata": {},
   "source": [
    "## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "–ú–æ–¥–µ–ª—å|–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—ã—á–Ω–æ–≥–æ –±–µ–π–∑–ª–∞–π–Ω–∞| –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –±–µ–π–∑–ª–∞–π–Ω–∞   |\n",
    "|---|---|---------------------------------|\n",
    "|YOLOv8n|mAP@0.5 = 0.542| mAP@0.5 = 0.542|\n",
    "|–ú–æ—è YOLOv8n|mAP@0.5 = 0.0341 | mAP@0.5 = 0.0292  |\n",
    "\n",
    "–ü—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –±–µ–π–∑–ª–∞–π–Ω–∞—Ö –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –æ–∫–∞–∑—ã–≤–∞–ª–∏—Å—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ –º–æ–∏—Ö –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–π"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
